import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,o as e,e as l}from"./app-BS_pjsAE.js";const o={},i=l('<blockquote></blockquote><p>TODO [ ] 搭建 llama3 模型，并调用成功 [ ] 整合 go 语言，实现 api 调用 [ ] 流式回复</p><p>以 llama3 为例： https://ollama.com/library/llama3</p><p>参考：</p><ul><li>https://zhuanlan.zhihu.com/p/694843237</li><li>https://blog.csdn.net/tirestay/article/details/139744309</li><li>https://blog.csdn.net/qq_40999403/article/details/139320266</li><li>视频参考： https://www.bilibili.com/video/av1903594994/?vd_source=f2a0231e07e27f42fa11f05024479cb8</li><li></li></ul><h2 id="附录" tabindex="-1"><a class="header-anchor" href="#附录"><span>附录</span></a></h2><ul><li>支持模型列表： https://ollama.com/library</li><li>中文参考文档： https://ollama.fan/reference/api/#generate-a-completion-request-streaming</li></ul>',7),n=[i];function r(p,c){return e(),a("div",null,n)}const h=t(o,[["render",r],["__file","ollama.html.vue"]]),d=JSON.parse('{"path":"/posts/ai/ollama.html","title":"ollama本地调用大模型","lang":"zh-CN","frontmatter":{"title":"ollama本地调用大模型","icon":"lightbulb","author":"Wang Shiyu","date":"2022-07-04T00:00:00.000Z","category":["ollama","ai"],"tag":["ollama","ai","llama3"],"description":"TODO [ ] 搭建 llama3 模型，并调用成功 [ ] 整合 go 语言，实现 api 调用 [ ] 流式回复 以 llama3 为例： https://ollama.com/library/llama3 参考： https://zhuanlan.zhihu.com/p/694843237 https://blog.csdn.net/tires...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/posts/ai/ollama.html"}],["meta",{"property":"og:site_name","content":"JavaPub"}],["meta",{"property":"og:title","content":"ollama本地调用大模型"}],["meta",{"property":"og:description","content":"TODO [ ] 搭建 llama3 模型，并调用成功 [ ] 整合 go 语言，实现 api 调用 [ ] 流式回复 以 llama3 为例： https://ollama.com/library/llama3 参考： https://zhuanlan.zhihu.com/p/694843237 https://blog.csdn.net/tires..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-07-06T13:42:36.000Z"}],["meta",{"property":"article:author","content":"Wang Shiyu"}],["meta",{"property":"article:tag","content":"ollama"}],["meta",{"property":"article:tag","content":"ai"}],["meta",{"property":"article:tag","content":"llama3"}],["meta",{"property":"article:published_time","content":"2022-07-04T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-07-06T13:42:36.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ollama本地调用大模型\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2022-07-04T00:00:00.000Z\\",\\"dateModified\\":\\"2024-07-06T13:42:36.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Wang Shiyu\\"}]}"]]},"headers":[{"level":2,"title":"附录","slug":"附录","link":"#附录","children":[]}],"git":{"createdTime":1720098956000,"updatedTime":1720273356000,"contributors":[{"name":"wangshiyu","email":"iswangshiyu@foxmail.com","commits":2}]},"readingTime":{"minutes":0.32,"words":95},"filePathRelative":"posts/ai/ollama.md","localizedDate":"2022年7月4日","excerpt":"<blockquote></blockquote>\\n<p>TODO\\n[ ] 搭建 llama3 模型，并调用成功\\n[ ] 整合 go 语言，实现 api 调用\\n[ ] 流式回复</p>\\n<p>以 llama3 为例： https://ollama.com/library/llama3</p>\\n<p>参考：</p>\\n<ul>\\n<li>https://zhuanlan.zhihu.com/p/694843237</li>\\n<li>https://blog.csdn.net/tirestay/article/details/139744309</li>\\n<li>https://blog.csdn.net/qq_40999403/article/details/139320266</li>\\n<li>视频参考： https://www.bilibili.com/video/av1903594994/?vd_source=f2a0231e07e27f42fa11f05024479cb8</li>\\n<li></li>\\n</ul>","autoDesc":true}');export{h as comp,d as data};
