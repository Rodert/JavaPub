import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,f as r,a as n,e as t,o}from"./app-BS_pjsAE.js";const i={},s=n("p",null,"kafka",-1),p=t(`<p>10道不得不会的 Kafka 面试题</p><p>我是JavaPub，专注于面试、副业，技术人的成长记录。</p><p>以下是 Kafka 面试题，相信大家都会有种及眼熟又陌生的感觉、看过可能在短暂的面试后又马上忘记了。<strong>JavaPub</strong>在这里整理这些容易忘记的重点知识及<strong>解答</strong>，<code>建议收藏，经常温习查阅</code>。</p><p>评论区见</p><p>@[toc]</p><h1 id="kafka" tabindex="-1"><a class="header-anchor" href="#kafka"><span>Kafka</span></a></h1><p>在面试kafka中，一定要了解为什么要用kafka、及kafka的架构等基本概念，才能对面试中的问题得心应手。</p><h2 id="术语0-kafka中的isr、ar又代表什么-isr的伸缩又指什么" tabindex="-1"><a class="header-anchor" href="#术语0-kafka中的isr、ar又代表什么-isr的伸缩又指什么"><span>术语0. Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么</span></a></h2><p><strong>ISR</strong>:In-Sync Replicas 副本同步队列</p><p><strong>AR</strong>:Assigned Replicas 所有副本</p><p>ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。</p><h2 id="术语0-kafka中的hw、leo、lso、lw等分别代表什么" tabindex="-1"><a class="header-anchor" href="#术语0-kafka中的hw、leo、lso、lw等分别代表什么"><span>术语0. Kafka中的HW、LEO、LSO、LW等分别代表什么？</span></a></h2><p><strong>HW</strong>:High Watermark 高水位，取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置上一条信息。</p><p><strong>LEO</strong>:LogEndOffset 当前日志文件中下一条待写信息的offset HW/LEO这两个都是指最后一条的下一条的位置而不是指最后一条的位置。</p><p><strong>LSO</strong>:Last Stable Offset 对未完成的事务而言，LSO 的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同</p><p><strong>LW</strong>:Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值</p><hr><h3 id="_1-kafka-是什么-有什么作用" tabindex="-1"><a class="header-anchor" href="#_1-kafka-是什么-有什么作用"><span>1. kafka 是什么？有什么作用？</span></a></h3><p>Kafka 是一个分布式的流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用</p><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-094144.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>主要功能体现于三点：</p><ul><li><p><strong>消息系统</strong>：kafka与传统的消息中间件都具备<strong>系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性</strong>等功能。与此同时，kafka还提供了大多数消息系统难以实现的消息顺序性保障及回溯性消费的功能。</p></li><li><p><strong>存储系统</strong>：kafka把<strong>消息持久化到磁盘</strong>，相比于其他基于内存存储的系统而言，有效的降低了消息丢失的风险。这得益于其消息持久化和多副本机制。也可以将kafka作为长期的存储系统来使用，只需要把对应的数据保留策略设置为“永久”或启用主题日志压缩功能。</p></li><li><p><strong>流式处理平台</strong>：kafka为流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理框架，比如窗口、连接、变换和聚合等各类操作。</p></li></ul><h3 id="_2-kafka-的架构是怎么样的" tabindex="-1"><a class="header-anchor" href="#_2-kafka-的架构是怎么样的"><span>2. kafka 的架构是怎么样的？</span></a></h3><blockquote><p>这是一个基本概念的题目，一定要掌握。</p></blockquote><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-094148.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>一个典型的 kafka 体系架构包括若干 Producer、若干 Consumer、以及一个 Zookeeper 集群（在2.8.0版本中移，除了 Zookeeper,通过 KRaft 进行自己的集群管理）</p><p>Producer 将消息发送到 Broker，Broker 负责将受到的消息存储到磁盘中，而 Consumer 负责从 Broker 订阅并消费消息。</p><p>Kafka 基本概念：</p><ul><li><p><strong>Producer</strong> ：生产者，负责将消息发送到 Broker</p></li><li><p><strong>Consumer</strong> ：消费者，从 Broker 接收消息</p></li><li><p><strong>Consumer Group</strong> ：消费者组，由多个 Consumer 组成。消费者组内每个消费者负责消费不同分区的数据，<strong>一个分区只能由一个组内消费者消费</strong>，消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p></li><li><p><strong>Broker</strong> ：可以看做一个独立的 <strong>Kafka 服务节点或 Kafka 服务实例</strong>。如果一台服务器上只部署了一个 Kafka 实例，那么我们也可以将 Broker 看做一台 Kafka 服务器。</p></li><li><p><strong>Topic</strong> ：一个逻辑上的概念，包含很多 Partition，<strong>同一个 Topic 下的 Partiton 的消息内容是不相同的</strong>。</p></li><li><p><strong>Partition</strong> ：为了实现扩展性，一个非常大的 topic <strong>可以分布到多个 broker 上，一个 topic 可以分为多个 partition</strong>，每个 partition 是一个有序的队列。</p></li><li><p><strong>Replica</strong> ：副本，<strong>同一分区的不同副本保存的是相同的消息</strong>，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，- kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。</p></li><li><p><strong>Leader</strong> ：每个分区的多个副本中的&quot;主副本&quot;，<strong>生产者以及消费者只与 Leader 交互</strong>。</p></li><li><p><strong>Follower</strong> ：每个分区的多个副本中的&quot;从副本&quot;，<strong>负责实时从 Leader 中同步数据，保持和 Leader 数据的同步</strong>。Leader 发生故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。</p></li></ul><h3 id="_3-kafka-replicas是怎么管理的" tabindex="-1"><a class="header-anchor" href="#_3-kafka-replicas是怎么管理的"><span>3. Kafka Replicas是怎么管理的？</span></a></h3><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-094151.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li>AR:分区中的<strong>所有 Replica 统称为 AR</strong></li><li>ISR:所有与 Leader 副本<strong>保持一定程度同步</strong>的Replica(包括 Leader 副本在内)组成 ISR</li><li>OSR:与 Leader 副本<strong>同步滞后过多的</strong> Replica 组成了 OSR</li></ul><p>Leader 负责维护和跟踪 ISR 集合中所有 Follower 副本的滞后状态，当 Follower 副本落后过多时，就会将其放入 OSR 集合，当 Follower 副本追上了 Leader 的进度时，就会将其放入 ISR 集合。</p><p>默认情况下，只有 <strong>ISR 中的副本才有资格晋升为 Leader</strong>。</p><h3 id="_4-如何确定当前能读到哪一条消息" tabindex="-1"><a class="header-anchor" href="#_4-如何确定当前能读到哪一条消息"><span>4. 如何确定当前能读到哪一条消息？</span></a></h3><blockquote><p>这个问题要先了解上一个问题的概念</p></blockquote><p>分区相当于一个日志文件，我们先简单介绍几个概念</p><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092656.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>如上图是一个分区日志文件</p><ul><li>标识<strong>共有7条消息</strong>，offset (消息偏移量)分别是0~6</li><li>0 代表这个日志文件的<strong>开始</strong></li><li>HW(High Watermark) 为4，0~3 代表这个日志文件<strong>可以消费的区间</strong>，消费者只能消费到这四条消息</li><li>LEO 代表即将要写入消息的偏移量 offset</li></ul><p><strong>分区 ISR 集合中的每个副本都会维护自己的 LEO，而 ISR 集合中最小的LEO 即为分区的 HW</strong></p><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092658.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>如上图: 三个分区副本都是 ISR集合当中的，最小的 LEO 为 3，就代表分区的 HW 为3，所以当前分区只能消费到 0~2 之间的三条数据，如下图</p><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092700.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="_5-发送消息的分区策略有哪些" tabindex="-1"><a class="header-anchor" href="#_5-发送消息的分区策略有哪些"><span>5. 发送消息的分区策略有哪些？</span></a></h3><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092703.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li><p>1.轮询：<strong>依次</strong>将消息发送该topic下的所有分区，如果在创建消息的时候 key 为 null，Kafka 默认采用这种策略。</p></li><li><p>2.key 指定分区：在创建消息是 key 不为空，并且使用默认分区器，Kafka 会将 key 进行 hash，然后<strong>根据hash值映射到指定的分区上</strong>。这样的好处是 key 相同的消息会在一个分区下，Kafka 并不能保证全局有序，但是在每个分区下的消息是有序的，按照顺序存储，按照顺序消费。在保证同一个 key 的消息是有序的，这样基本能满足消息的顺序性的需求。但是<strong>如果 partation 数量发生变化，那就很难保证 key 与分区之间的映射关系了</strong>。</p></li><li><p>3.自定义策略：实现 Partitioner 接口就能自定义分区策略。</p></li><li><p>4.指定 Partiton 发送</p></li></ul><h3 id="_6-kafka-的可靠性是怎么保证的" tabindex="-1"><a class="header-anchor" href="#_6-kafka-的可靠性是怎么保证的"><span>6. Kafka 的可靠性是怎么保证的？</span></a></h3><p><strong>1.acks</strong></p><p>这个参数用来指定分区中有多少个副本收到这条消息，生产者才认为这条消息是写入成功的，这个参数有三个值：</p><ul><li>1.acks = 1，默认为1。生产者发送消息，<strong>只要 leader 副本成功写入消息，就代表成功</strong>。这种方案的问题在于，当返回成功后，如果 leader 副本和 follower 副本<strong>还没有来得及同步</strong>，leader 就崩溃了，那么在选举后新的 leader 就没有这条<strong>消息，也就丢失了</strong>。</li><li>2.acks = 0。生产者发送消息后直接算写入成功，不需要等待响应。这个方案的问题很明显，<strong>只要服务端写消息时出现任何问题，都会导致消息丢失</strong>。</li><li>3.acks = -1 或 acks = all。生产者发送消息后，需要等待 ISR 中的所有副本都成功写入消息后才能收到服务端的响应。毫无疑问这种方案的<strong>可靠性是最高的</strong>，但是如果 ISR 中只有leader 副本，那么就和 acks = 1 毫无差别了。</li></ul><p><strong>2.消息发送的方式</strong></p><p>第6问中我们提到了生产者发送消息有三种方式，发完即忘，同步和异步。我们可以通过同步或者异步获取响应结果，<strong>失败做重试</strong>来保证消息的可靠性。</p><p><strong>3.手动提交位移</strong></p><p>默认情况下，当消费者消费到消息后，就会自动提交位移。但是如果消费者消费出错，没有进入真正的业务处理，那么就可能会导致这条消息消费失败，从而丢失。我们可以开启手动提交位移，等待业务正常处理完成后，再提交offset。</p><p><strong>4.通过副本 LEO 来确定分区 HW</strong></p><p>可参考第四问</p><h3 id="_7-分区再分配是做什么的-解决了什么问题" tabindex="-1"><a class="header-anchor" href="#_7-分区再分配是做什么的-解决了什么问题"><span>7. 分区再分配是做什么的？解决了什么问题？</span></a></h3><p>分区再分配主要是用来维护 kafka 集群的负载均衡</p><p>既然是分区再分配，那么 kafka 分区有什么问题呢？</p><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092706.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>问题1</strong>：当集群中的一个节点下线了</p><ul><li>如果该节点的分区是单副本的,那么分区将会变得不可用</li><li>如果是多副本的，就会进行 leader 选举，在其他机器上选举出新的 leader</li></ul><p><strong>kafka 并不会将这些失效的分区迁移到其他可用的 broker 上</strong>，这样就会影响集群的负载均衡，甚至也会影响服务的可靠性和可用性</p><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092708.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>问题2</strong>：集群新增 broker 时，只有新的主题分区会分配在该 broker 上，而老的主题分区不会分配在该 broker 上，就造成了<strong>老节点和新节点之间的负载不均衡</strong>。</p><p>为了解决该问题就出现了分区再分配，它可以在集群扩容，broker 失效的场景下进行分区迁移。</p><p><strong>分区再分配的原理就是通化控制器给分区新增新的副本，然后通过网络把旧的副本数据复制到新的副本上，在复制完成后，将旧副本清除</strong>。 当然，为了不影响集群正常的性能，在此复制期间还会有一系列保证性能的操作，比如<strong>复制限流</strong>。</p><h3 id="_8-kafka-partition-副本-leader-是怎么选举的" tabindex="-1"><a class="header-anchor" href="#_8-kafka-partition-副本-leader-是怎么选举的"><span>8. Kafka Partition 副本 leader 是怎么选举的？</span></a></h3><blockquote><p>这个问题设计的点比较多，拓展的也更多一点，建议耐心阅读。</p></blockquote><p><strong>常用选主机制的缺点：</strong></p><div class="language-xml line-numbers-mode" data-highlighter="shiki" data-ext="xml" data-title="xml" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">split-brain (脑裂):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">​这是由ZooKeeper的特性引起的，虽然ZooKeeper能保证所有Watch按顺序触发，但是网络延迟，并不能保证同一时刻所有Replica“看”到的状态是一样的，这就可能造成不同Replica的响应不一致，可能选出多个领导“大脑”，导致“脑裂”。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">herd effect (羊群效应):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">​如果宕机的那个Broker上的Partition比较多， 会造成多个Watch被触发，造成集群内大量的调整，导致大量网络阻塞。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">ZooKeeper负载过重:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">​每个Replica都要为此在ZooKeeper上注册一个Watch，当集群规模增加到几千个Partition时ZooKeeper负载会过重。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>优势：</strong></p><p>Kafka的Leader Election方案解决了上述问题，它在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。 controller会将Leader的改变直接通过RPC的方式(比ZooKeeper Queue的方式更高效)通知需为此作为响应的Broker。</p><p>没有使用 zk，所以无 2.3 问题；也没有注册 watch无 2.2 问题 leader 失败了，就通过 controller 继续重新选举即可，所以克服所有问题。</p><p><strong>Kafka partition leader的选举：</strong></p><p>由 controller 执行：</p><ul><li>从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合</li><li>调用配置的分区选择算法选择分区的leader</li></ul><figure><img src="https://tvax1.sinaimg.cn/large/007F3CC8ly1h3dl7rqe24j313c0nm7ik.jpg" alt="分区选择算法" tabindex="0" loading="lazy"><figcaption>分区选择算法</figcaption></figure><p>上面五种分区算法都是选择PreferredReplica(优先副本选举)作为当前Partition的leader。区别仅仅是选择leader之后的操作有所不同。</p><h3 id="_9-分区数越多越好吗-吞吐量就会越高吗" tabindex="-1"><a class="header-anchor" href="#_9-分区数越多越好吗-吞吐量就会越高吗"><span>9. 分区数越多越好吗？吞吐量就会越高吗？</span></a></h3><p>般类似于这种问题的答案，都是持否定态度的。</p><p>但是可以说，<strong>在一定条件下，分区数的数量是和吞吐量成正比的，分区数和性能也是成正比的</strong>。</p><p>那么为什么说超过了一定限度，就会对性能造成影响呢？原因如下:</p><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092711.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>1.客户端/服务器端需要使用的内存就越多</strong></p><p>服务端在很多组件中都维护了分区级别的缓存，分区数越大，缓存成本也就越大。 消费端的消费线程数是和分区数挂钩的，分区数越大消费线程数也就越多，线程的开销成本也就越大 生产者发送消息有缓存的概念，会为每个分区缓存消息，当积累到一定程度或者时间时会将消息发送到分区，分区越多，这部分的缓存也就越大</p><p><strong>2.文件句柄的开销</strong></p><p>每个 partition 都会对应磁盘文件系统的一个目录。在 Kafka 的数据日志文件目录中，每个日志数据段都会分配两个文件，一个索引文件和一个数据文件。每个 broker 会为每个日志段文件打开一个 index 文件句柄和一个数据文件句柄。因此，随着 partition 的增多，所需要保持打开状态的文件句柄数也就越多，最终可能超过底层操作系统配置的文件句柄数量限制。</p><p><strong>3.越多的分区可能增加端对端的延迟</strong></p><p>Kafka 会将分区 HW 之前的消息暴露给消费者。分区越多则副本之间的同步数量就越多，在默认情况下，每个 broker 从其他 broker 节点进行数据副本复制时，该 broker 节点只会为此工作分配一个线程，该线程需要完成该 broker 所有 partition 数据的复制。</p><p><strong>4.降低高可用性</strong></p><p>在第 7 问我们提到了分区再分配，会将数据复制到另一份副本当中，<strong>分区数量越多，那么恢复时间也就越长</strong>，而如果发生宕机的 broker 恰好是 controller 节点时：在这种情况下，新 leader 节点的选举过程在 controller 节点恢复到新的 broker 之前不会启动。controller 节点的错误恢复将会自动地进行，但是新的 controller 节点需要从 zookeeper 中读取每一个 partition 的元数据信息用于初始化数据。例如，假设一个Kafka 集群存在 10000个partition，从 zookeeper 中恢复元数据时每个 partition 大约花费 2 ms，则 controller 的恢复将会增加约 20 秒的不可用时间窗口。</p><h3 id="_10-kafka-为什么这么快" tabindex="-1"><a class="header-anchor" href="#_10-kafka-为什么这么快"><span>10. kafka 为什么这么快？</span></a></h3><figure><img src="https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092714.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li><p>1.<strong>顺序读写</strong>磁盘分为顺序读写与随机读写，基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，kafka 这里采用的就是顺序读写。</p></li><li><p>2.<strong>Page Cache</strong>为了优化读写性能，Kafka 利用了<strong>操作系统本身的 Page Cache</strong>，就是利用操作系统自身的内存而不是JVM空间内存。</p></li><li><p>3.<strong>零拷贝</strong>Kafka使用了零拷贝技术，也就是<strong>直接将数据从内核空间的读缓冲区直接拷贝到内核空间的 socket 缓冲区</strong>，然后再写入到 NIC 缓冲区，避免了在内核空间和用户空间之间穿梭。</p></li><li><p>4.<strong>分区分段+索引</strong>Kafka 的 message 是按 topic分 类存储的，topic 中的数据又是按照一个一个的 partition 即分区存储到不同 broker 节点。每个 partition 对应了操作系统上的一个文件夹，partition 实际上又是按照segment分段存储的。通过这种分区分段的设计，Kafka 的 message 消息实际上是分布式存储在一个一个小的 segment 中的，每次文件操作也是直接操作的 segment。为了进一步的查询优化，Kafka 又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。</p></li><li><p>5.<strong>批量读写Kafka 数据读写也是批量的而不是单条的</strong>,这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。</p></li><li><p>6.<strong>批量压缩</strong>Kafka 把所有的消息都变成一个<strong>批量的文件</strong>，并且进行合理的<strong>批量压缩</strong>，减少网络 IO 损耗，通过 mmap 提高 I/O 速度，写入数据的时候由于单个Partion是末尾添加所以速度最优；读取数据的时候配合 sendfile 进行直接读取。</p></li></ul><p>低谷蓄力</p><h2 id="《最少必要面试题》" tabindex="-1"><a class="header-anchor" href="#《最少必要面试题》"><span>《最少必要面试题》</span></a></h2><p><a href="https://mp.weixin.qq.com/s/3Nviyml0cvnX_HHkZ5DjWg" target="_blank" rel="noopener noreferrer">10道不得不会的Java基础面试题</a></p><p><a href="https://mp.weixin.qq.com/s/ug3LBR4MfM1C5uVFJaPWLQ" target="_blank" rel="noopener noreferrer">10道不得不会的Java容器面试题</a></p><p><a href="https://mp.weixin.qq.com/s/h2tTwDVqL15rCI6rftgn9A" target="_blank" rel="noopener noreferrer">10道不得不会的Java并发基础面试题</a></p><p><a href="https://mp.weixin.qq.com/s/59Tif95LGi8BTJXu47zi6g" target="_blank" rel="noopener noreferrer">10道不得不会的JavaEE面试题</a></p><p><a href="https://mp.weixin.qq.com/s/hvsaD1NlzpR0LpP-GmbU_A" target="_blank" rel="noopener noreferrer">10道不得不会的JVM面试题</a></p><p><a href="https://mp.weixin.qq.com/s/yVPwCoSQ-8OYvhw8bH0PtA" target="_blank" rel="noopener noreferrer">10道不得不会的MySQL基础面试题</a></p><p><a href="https://mp.weixin.qq.com/s/lVFwy765hQ2FvIYBHyw0yA" target="_blank" rel="noopener noreferrer">10道不得不会的MyBatis面试题</a></p><p><a href="https://mp.weixin.qq.com/s/lrHsLZANxHxd_FWTCdMNJw" target="_blank" rel="noopener noreferrer">10道不得不会的Spring面试题</a></p><p><a href="https://mp.weixin.qq.com/s/-oYKVXBaQwzyzp7ffqH7gw" target="_blank" rel="noopener noreferrer">10道不得不会的SpringBoot面试题</a></p><p><a href="https://mp.weixin.qq.com/s/z3D37HqeTUmwrdheUL_Efw" target="_blank" rel="noopener noreferrer">10道不得不会的ElasticSearch面试题</a></p><p><a href="https://mp.weixin.qq.com/s/_Pq2VgxRA4yw1j_eCfEiLg" target="_blank" rel="noopener noreferrer">10道不得不会的Redis面试题</a></p><p><a href="https://javapub.blog.csdn.net/category_11740063.html" target="_blank" rel="noopener noreferrer">10道不得不会的Kafka面试题</a></p><p><a href="https://mp.weixin.qq.com/s/ym0-x6okFi0CgF8RcxeLFA" target="_blank" rel="noopener noreferrer">10道不得不会的Zookeeper面试题</a></p><p><a href="https://mp.weixin.qq.com/s/DTC3gZNHm3Rlf_GK7twlkQ" target="_blank" rel="noopener noreferrer">10道不得不会的Docker面试题</a></p><p><a href="">10道不得不会的缓存面试题</a></p><p><a href="https://github.com/Rodert" target="_blank" rel="noopener noreferrer">GItHub</a>|<a href="https://gitee.com/rodert" target="_blank" rel="noopener noreferrer">GitEE</a></p>`,114);function l(g,c){return o(),e("div",null,[s,r(" more "),p])}const h=a(i,[["render",l],["__file","kafka-interview-must.html.vue"]]),m=JSON.parse('{"path":"/posts/special/havato/kafka-interview-must.html","title":"10道不得不会的 Kafka 面试题","lang":"zh-CN","frontmatter":{"index":true,"icon":"page","title":"10道不得不会的 Kafka 面试题","author":"Wang Shiyu","date":"2022-06-19T00:00:00.000Z","category":["最少必要面试题"],"tag":["kafka","面试题"],"description":"kafka","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/posts/special/havato/kafka-interview-must.html"}],["meta",{"property":"og:site_name","content":"JavaPub"}],["meta",{"property":"og:title","content":"10道不得不会的 Kafka 面试题"}],["meta",{"property":"og:description","content":"kafka"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-094144.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-07-03T14:35:52.000Z"}],["meta",{"property":"article:author","content":"Wang Shiyu"}],["meta",{"property":"article:tag","content":"kafka"}],["meta",{"property":"article:tag","content":"面试题"}],["meta",{"property":"article:published_time","content":"2022-06-19T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-07-03T14:35:52.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"10道不得不会的 Kafka 面试题\\",\\"image\\":[\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-094144.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-094148.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-094151.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092656.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092658.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092700.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092703.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092706.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092708.png\\",\\"https://tvax1.sinaimg.cn/large/007F3CC8ly1h3dl7rqe24j313c0nm7ik.jpg\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092711.png\\",\\"https://javapub-common-oss.oss-cn-beijing.aliyuncs.com/javapub/2024%2F06%2F15%2F20240615-092714.png\\"],\\"datePublished\\":\\"2022-06-19T00:00:00.000Z\\",\\"dateModified\\":\\"2024-07-03T14:35:52.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Wang Shiyu\\"}]}"]]},"headers":[{"level":2,"title":"术语0. Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么","slug":"术语0-kafka中的isr、ar又代表什么-isr的伸缩又指什么","link":"#术语0-kafka中的isr、ar又代表什么-isr的伸缩又指什么","children":[]},{"level":2,"title":"术语0. Kafka中的HW、LEO、LSO、LW等分别代表什么？","slug":"术语0-kafka中的hw、leo、lso、lw等分别代表什么","link":"#术语0-kafka中的hw、leo、lso、lw等分别代表什么","children":[{"level":3,"title":"1. kafka 是什么？有什么作用？","slug":"_1-kafka-是什么-有什么作用","link":"#_1-kafka-是什么-有什么作用","children":[]},{"level":3,"title":"2. kafka 的架构是怎么样的？","slug":"_2-kafka-的架构是怎么样的","link":"#_2-kafka-的架构是怎么样的","children":[]},{"level":3,"title":"3. Kafka Replicas是怎么管理的？","slug":"_3-kafka-replicas是怎么管理的","link":"#_3-kafka-replicas是怎么管理的","children":[]},{"level":3,"title":"4. 如何确定当前能读到哪一条消息？","slug":"_4-如何确定当前能读到哪一条消息","link":"#_4-如何确定当前能读到哪一条消息","children":[]},{"level":3,"title":"5. 发送消息的分区策略有哪些？","slug":"_5-发送消息的分区策略有哪些","link":"#_5-发送消息的分区策略有哪些","children":[]},{"level":3,"title":"6. Kafka 的可靠性是怎么保证的？","slug":"_6-kafka-的可靠性是怎么保证的","link":"#_6-kafka-的可靠性是怎么保证的","children":[]},{"level":3,"title":"7. 分区再分配是做什么的？解决了什么问题？","slug":"_7-分区再分配是做什么的-解决了什么问题","link":"#_7-分区再分配是做什么的-解决了什么问题","children":[]},{"level":3,"title":"8. Kafka Partition 副本 leader 是怎么选举的？","slug":"_8-kafka-partition-副本-leader-是怎么选举的","link":"#_8-kafka-partition-副本-leader-是怎么选举的","children":[]},{"level":3,"title":"9. 分区数越多越好吗？吞吐量就会越高吗？","slug":"_9-分区数越多越好吗-吞吐量就会越高吗","link":"#_9-分区数越多越好吗-吞吐量就会越高吗","children":[]},{"level":3,"title":"10. kafka 为什么这么快？","slug":"_10-kafka-为什么这么快","link":"#_10-kafka-为什么这么快","children":[]}]},{"level":2,"title":"《最少必要面试题》","slug":"《最少必要面试题》","link":"#《最少必要面试题》","children":[]}],"git":{"createdTime":1717582746000,"updatedTime":1720017352000,"contributors":[{"name":"wangshiyu","email":"iswangshiyu@foxmail.com","commits":1}]},"readingTime":{"minutes":16.19,"words":4856},"filePathRelative":"posts/special/havato/kafka-interview-must.md","localizedDate":"2022年6月19日","excerpt":"<p>kafka</p>\\n","autoDesc":true}');export{h as comp,m as data};
